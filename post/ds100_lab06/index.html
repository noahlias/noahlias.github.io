<!doctype html><html lang=en><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge,chrome=1"><title>Lab06_WriteUp - Alias's Blog</title><meta name=renderer content="webkit"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta http-equiv=cache-control content="no-transform"><meta http-equiv=cache-control content="no-siteapp"><meta name=theme-color content="#f8f5ec"><meta name=msapplication-navbutton-color content="#f8f5ec"><meta name=apple-mobile-web-app-capable content="yes"><meta name=apple-mobile-web-app-status-bar-style content="#f8f5ec"><meta name=author content="Alias"><meta name=description content="模型, 统计, 损失函数 损失函数 损失函数是我们用来确定我们模型的最佳参数的。 损失函数是对一个模型能够预测预期结果的程度的一种衡量。换句话说，它衡"><meta name=keywords content="Coding,Blog,Life"><meta name=generator content="Hugo 0.108.0 with theme even"><link rel=canonical href=https://noahlias.github.io/post/ds100_lab06/><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/manifest.json><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link href=/sass/main.min.b5a744db6de49a86cadafb3b70f555ab443f83c307a483402259e94726b045ff.css rel=stylesheet><meta property="og:title" content="Lab06_WriteUp"><meta property="og:description" content="模型, 统计, 损失函数 损失函数 损失函数是我们用来确定我们模型的最佳参数的。 损失函数是对一个模型能够预测预期结果的程度的一种衡量。换句话说，它衡"><meta property="og:type" content="article"><meta property="og:url" content="https://noahlias.github.io/post/ds100_lab06/"><meta property="article:section" content="post"><meta property="article:published_time" content="2022-11-18T19:33:03+08:00"><meta property="article:modified_time" content="2022-11-18T19:33:03+08:00"><meta itemprop=name content="Lab06_WriteUp"><meta itemprop=description content="模型, 统计, 损失函数 损失函数 损失函数是我们用来确定我们模型的最佳参数的。 损失函数是对一个模型能够预测预期结果的程度的一种衡量。换句话说，它衡"><meta itemprop=datePublished content="2022-11-18T19:33:03+08:00"><meta itemprop=dateModified content="2022-11-18T19:33:03+08:00"><meta itemprop=wordCount content="511"><meta itemprop=keywords content="Statistics,Model,Writeup,"><meta name=twitter:card content="summary"><meta name=twitter:title content="Lab06_WriteUp"><meta name=twitter:description content="模型, 统计, 损失函数 损失函数 损失函数是我们用来确定我们模型的最佳参数的。 损失函数是对一个模型能够预测预期结果的程度的一种衡量。换句话说，它衡"><!--[if lte IE 9]><script src=https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js></script><![endif]--><!--[if lt IE 9]><script src=https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js></script>
<script src=https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js></script><![endif]--></head><body><div id=mobile-navbar class=mobile-navbar><div class=mobile-header-logo><a href=/ class=logo>Alias</a></div><div class=mobile-navbar-icon><span></span>
<span></span>
<span></span></div></div><nav id=mobile-menu class="mobile-menu slideout-menu"><ul class=mobile-menu-list><a href=/><li class=mobile-menu-item>Home</li></a><a href=/post/><li class=mobile-menu-item>Archives</li></a><a href=/tags/><li class=mobile-menu-item>Tags</li></a><a href=/categories/><li class=mobile-menu-item>Categories</li></a><a href=/about/><li class=mobile-menu-item>About</li></a></ul></nav><div class=container id=mobile-panel><header id=header class=header><div class=logo-wrapper><a href=/ class=logo>Alias</a></div><nav class=site-navbar><ul id=menu class=menu><li class=menu-item><a class=menu-item-link href=/>Home</a></li><li class=menu-item><a class=menu-item-link href=/post/>Archives</a></li><li class=menu-item><a class=menu-item-link href=/tags/>Tags</a></li><li class=menu-item><a class=menu-item-link href=/categories/>Categories</a></li><li class=menu-item><a class=menu-item-link href=/about/>About</a></li></ul></nav></header><main id=main class=main><div class=content-wrapper><div id=content class=content><article class=post><header class=post-header><h1 class=post-title>Lab06_WriteUp</h1><div class=post-meta><span class=post-time>2022-11-18</span><div class=post-category><a href=/categories/ds100/>DS100</a></div></div></header><div class=post-toc id=post-toc><h2 class=post-toc-title>Contents</h2><div class=post-toc-content><nav id=TableOfContents><ul><li><ul><li><a href=#模型-统计-损失函数><strong>模型, 统计, 损失函数</strong></a><ul><li><a href=#损失函数>损失函数</a></li><li><a href=#区别>区别</a></li></ul></li></ul></li></ul></nav></div></div><div class=post-content><a target=_blank href=https://colab.research.google.com/github/DS-100/fa20/blob/master/lab/lab06/lab06.ipynb><img src=https://colab.research.google.com/assets/colab-badge.svg alt="Open In Colab"></a><h2 id=模型-统计-损失函数><strong>模型, 统计, 损失函数</strong></h2><h3 id=损失函数>损失函数</h3><p>损失函数是我们用来确定我们模型的最佳参数的。</p><p>损失函数是对一个模型能够预测预期结果的程度的一种衡量。换句话说，它衡量的是预测值与观察值的偏差。在这个实验室中，我们将实现平方损失和绝对损失函数。</p><p>下面公式里面$y$ 代表观察值，$\hat{y}$ 代表预测值</p><ol><li><strong>Squared Loss(平方损失)</strong> (也叫the $L_2$ 损失函数, 发音 &ldquo;ell-two&rdquo;):</li></ol><p>$$\Large L(y, \hat{y}) = (y - \hat{y})^2$$</p><ol><li><strong>Absolute Loss(绝对损失)</strong> ( 也叫$L_1$ 损失函数, 发音"ell-one"):</li></ol><p>$$\Large L\left(y, \hat{y} \right) = \left| y - \hat{y} \right|$$</p><p>我们使用如下的常量模型 $\hat{y} = \theta$ 做实验, 我们会用下面的两个函数 $(y - \theta)^2$ 和 $|y - \theta|$ 来代替上述提到的损失函数.</p><h4 id=平方损失>平方损失</h4><p>$$\Large
L\left(y, \theta \right) = \left( y - \theta \right)^2
$$</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>squared_loss</span><span class=p>(</span><span class=n>y_obs</span><span class=p>,</span> <span class=n>theta</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Calculate the squared loss of the observed data and a summary statistic.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Parameters
</span></span></span><span class=line><span class=cl><span class=s2>    ------------
</span></span></span><span class=line><span class=cl><span class=s2>    y_obs: an observed value
</span></span></span><span class=line><span class=cl><span class=s2>    theta : some constant representing a summary statistic
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Returns
</span></span></span><span class=line><span class=cl><span class=s2>    ------------
</span></span></span><span class=line><span class=cl><span class=s2>    The squared loss between the observation and the summary statistic.
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>np</span><span class=o>.</span><span class=n>power</span><span class=p>(</span><span class=n>y_obs</span><span class=o>-</span><span class=n>theta</span><span class=p>,</span><span class=mi>2</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>图例:</p><p><img src=/plot/lab06_1.jpg alt=square_loss></p><h4 id=绝对损失>绝对损失</h4><p>$$\Large
L\left(y, \theta \right) = \left| y - \theta \right|
$$</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>abs_loss</span><span class=p>(</span><span class=n>theta</span><span class=p>,</span> <span class=n>y_obs</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>np</span><span class=o>.</span><span class=n>abs</span><span class=p>(</span><span class=n>y_obs</span><span class=o>-</span><span class=n>theta</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>图例:
<img src=/plot/lab06_2.jpg alt=absolute_loss></p><h3 id=区别>区别</h3><p><code>MAE</code>(<em>平均绝对误差</em>) 与<code>MSE</code>(<em>均方误差</em>)的几个区别</p><ol><li>最小化的$\theta$是不同的。</li><li>当我们远离最小化$\theta$时，MAE的曲线呈线性增长，而不是呈二次增长。</li><li>MAE的曲线是线性的，而不是平滑的。斜率的每次变化都发生在我们数据集中的同一个$\theta$值</li></ol></div><div class=post-copyright><p class=copyright-item><span class=item-title>Author</span>
<span class=item-content>Alias</span></p><p class=copyright-item><span class=item-title>LastMod</span>
<span class=item-content>2022-11-18</span></p></div><footer class=post-footer><div class=post-tags><a href=/tags/statistics/>Statistics</a>
<a href=/tags/model/>Model</a>
<a href=/tags/writeup/>Writeup</a></div><nav class=post-nav><a class=prev href=/post/euler_19/><i class="iconfont icon-left"></i>
<span class="prev-text nav-default">Counting Sundays</span>
<span class="prev-text nav-mobile">Prev</span></a>
<a class=next href=/post/ds100_lab07/><span class="next-text nav-default">Lab07_WriteUp</span>
<span class="next-text nav-mobile">Next</span>
<i class="iconfont icon-right"></i></a></nav></footer></article></div><script src=https://utteranc.es/client.js repo=noahlias/noahlias.github.io issue-term=pathname theme=github-light crossorigin=anonymous async></script><noscript>Please enable JavaScript to view the <a href=https://github.com/utterance>comments powered by utterances.</a></noscript></div></main><footer id=footer class=footer><div class=social-links><a href=https://www.github.com/noahlias class="iconfont icon-github" title=github></a>
<a href=https://weibo.com/Alias21 class="iconfont icon-weibo" title=weibo></a>
<a href=https://space.bilibili.com/1741799 class="iconfont icon-bilibili" title=bilibili></a>
<a href=https://noahlias.github.io/index.xml type=application/rss+xml class="iconfont icon-rss" title=rss></a></div><div class=copyright><span class=power-by>Powered by <a class=hexo-link href=https://gohugo.io>Hugo</a></span>
<span class=division>|</span>
<span class=theme-info>Theme -
<a class=theme-link href=https://github.com/olOwOlo/hugo-theme-even>Even</a></span>
<span class=copyright-year>&copy;
2022<span class=heart><i class="iconfont icon-heart"></i></span><span>Alias</span></span></div></footer><div class=back-to-top id=back-to-top><i class="iconfont icon-up"></i></div></div><script src=https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin=anonymous></script>
<script type=text/javascript src=/js/main.min.4ae89da218555efa0e7093a20b92017d2e1202b66fff9fc2edf4cb8d44b44c6e.js></script>
<script type=text/javascript>window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]}}</script><script async src=https://cdn.jsdelivr.net/npm/mathjax@3.0.5/es5/tex-mml-chtml.js integrity="sha256-HGLuEfFcsUJGhvB8cQ8nr0gai9EucOOaIxFw7qxmd+w=" crossorigin=anonymous></script></body></html>